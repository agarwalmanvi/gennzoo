{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will train a Spiking Neural Network to perform digit recognition on the MNIST dataset. We will use the [SuperSpike](https://www.mitpressjournals.org/doi/pdf/10.1162/neco_a_01086) learning rule to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.data import loadlocal_mnist\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle as pkl\n",
    "from pygenn import genn_wrapper\n",
    "from pygenn import genn_model\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import create_poisson_spikes, get_mean_square_error\n",
    "from models.neurons.lif_superspike import (output_model_classification, OUTPUT_PARAMS, output_init_classification,\n",
    "                                           hidden_model, HIDDEN_PARAMS, hidden_init,\n",
    "                                           feedback_postsyn_model)\n",
    "from models.synapses.superspike import (superspike_model, SUPERSPIKE_PARAMS, superspike_init,\n",
    "                                        feedback_wts_model, feedback_wts_init)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "os.environ[\"CUDA_PATH\"] = \"/usr/local/cuda-11.0\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can use a SNN on the MNIST dataset, we will convert the samples from the MNIST dataset into spike latency values using the method described in [this paper](https://www.biorxiv.org/content/10.1101/2020.06.29.176925v1). This means that for every sample, the pixel values will be converted into firing times such that each of the 784 input neurons spike exactly once during a sample presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to change a vector of pixel values to a vector of latency-to-spike times\n",
    "def to_spike_latency(img_vec, t_eff, thresh):\n",
    "    img_vec = img_vec.flatten()\n",
    "    norm_img_vec = minmax_scale(img_vec, feature_range=(0, t_eff - 1))\n",
    "    spike_img_vec = np.where(norm_img_vec > thresh,\n",
    "                             t_eff * np.log(norm_img_vec / (norm_img_vec - thresh)),\n",
    "                             np.inf)\n",
    "    return spike_img_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we initialize a data structure to store the spike times for each pixel for each sample. We will populate `X_train_spike`, of size rows=60,000 and cols=784, with values corresponding to the latency-to-spike time for each pixel. Note that many values in this data structure will be `np.inf`, meaning that these input neurons should not spike during sample presentation. We will also do the same for the testing set. We round up the spike times to one decimal place because we will use a timestep of 0.1 ms in the simulation of our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./mnist\"\n",
    "T_EFF = 50  # ms\n",
    "THRESH = 0.2\n",
    "N_INPUT = 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process MNIST training dataset\n",
    "# X_train, y_train = loadlocal_mnist(\n",
    "#     images_path=os.path.join(data_dir, 'train-images-idx3-ubyte'),\n",
    "#     labels_path=os.path.join(data_dir, 'train-labels-idx1-ubyte'))\n",
    "# \n",
    "# X_train_spike = np.zeros(shape=X_train.shape)\n",
    "\n",
    "# for img_idx in range(X_train.shape[0]):\n",
    "#     if img_idx % 5000 == 0:\n",
    "#         print(\"Processing img \" + str(img_idx))\n",
    "#     img = X_train[img_idx, :]\n",
    "#     X_train_spike[img_idx, :] = to_spike_latency(img, T_EFF, THRESH)\n",
    "\n",
    "# X_train_spike = np.round(X_train_spike, decimals=1)\n",
    "# print(\"Training set size: \" + str(X_train_spike.shape))\n",
    "\n",
    "_, y_train = loadlocal_mnist(\n",
    "    images_path=os.path.join(data_dir, 'train-images-idx3-ubyte'),\n",
    "    labels_path=os.path.join(data_dir, 'train-labels-idx1-ubyte'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process MNIST testing dataset\n",
    "# X_test, y_test = loadlocal_mnist(\n",
    "#     images_path=os.path.join(data_dir, 't10k-images-idx3-ubyte'),\n",
    "#     labels_path=os.path.join(data_dir, 't10k-labels-idx1-ubyte'))\n",
    "\n",
    "# X_test_spike = np.zeros(shape=X_test.shape)\n",
    "\n",
    "# for img_idx in range(X_test.shape[0]):\n",
    "#     if img_idx % 1000 == 0:\n",
    "#         print(\"Processing img \" + str(img_idx))\n",
    "#     img = X_test[img_idx, :]\n",
    "#     X_test_spike[img_idx, :] = to_spike_latency(img, T_EFF, THRESH)\n",
    "\n",
    "# X_test_spike = np.round(X_test_spike, decimals=1)\n",
    "# print(\"Testing set size: \" + str(X_test_spike.shape))\n",
    "\n",
    "_, y_test = loadlocal_mnist(\n",
    "    images_path=os.path.join(data_dir, 't10k-images-idx3-ubyte'),\n",
    "    labels_path=os.path.join(data_dir, 't10k-labels-idx1-ubyte'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data in the right format, we can start setting up our network. Before building the model, we need to decide on how our trials shoud be structured. Following the trial design of XOR from SuperSpike, our trials will be comprised of three phases: sample presentation, waiting period (15 ms) and intertrial interval (50 ms). The length of the first phase will be set to the maximum finite spike latency of all samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stimulus timesteps: 37\n"
     ]
    }
   ],
   "source": [
    "# MAX_TIMESTEPS_TRAIN = np.ceil(np.amax(X_train_spike, where=~np.isinf(X_train_spike), initial=-1))  # ms\n",
    "# MAX_TIMESTEPS_TEST = np.ceil(np.amax(X_test_spike, where=~np.isinf(X_test_spike), initial=-1))  # ms\n",
    "# STIMULUS_TIMESTEPS = np.amax([MAX_TIMESTEPS_TEST, MAX_TIMESTEPS_TRAIN])  # ms\n",
    "STIMULUS_TIMESTEPS = 37\n",
    "print(\"Stimulus timesteps: \" + str(STIMULUS_TIMESTEPS))\n",
    "ITI = 50  # ms\n",
    "WAIT_TIMESTEPS = 15  # ms\n",
    "total_time = STIMULUS_TIMESTEPS + WAIT_TIMESTEPS + ITI "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also similar to the XOR task, we need to preprocess our samples into trials. We will use 5 epochs to train our networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trials(n_neurons, epochs, n_samples, sample_spike, stimulus_timesteps, \n",
    "                  wait_timesteps, iti, wait_freq, spike_dt, time_factor):\n",
    "    poisson_spikes = []\n",
    "\n",
    "    for neuron_idx in range(n_neurons):\n",
    "        if neuron_idx % 10 == 0:\n",
    "            print(\"Processing neuron \" + str(neuron_idx))\n",
    "        neuron_poisson_spikes = np.empty(0)\n",
    "        time_elapsed = 0\n",
    "        for epoch in range(epochs):\n",
    "            for trial_idx in range(n_samples):\n",
    "                sample_spike_time = sample_spike[trial_idx, neuron_idx]\n",
    "                if not np.isinf(sample_spike_time):\n",
    "                    sample_spike_time += time_elapsed\n",
    "                    neuron_poisson_spikes = np.hstack((neuron_poisson_spikes, sample_spike_time))\n",
    "                time_elapsed += stimulus_timesteps\n",
    "\n",
    "                wait_plus_iti = wait_timesteps + iti\n",
    "                wait_spike_times = create_poisson_spikes(wait_plus_iti, wait_freq, spike_dt, time_factor)\n",
    "                wait_spike_times += time_elapsed\n",
    "                neuron_poisson_spikes = np.hstack((neuron_poisson_spikes, wait_spike_times))\n",
    "                time_elapsed += wait_plus_iti\n",
    "\n",
    "        poisson_spikes.append(neuron_poisson_spikes)\n",
    "\n",
    "    spike_counts = [len(n) for n in poisson_spikes]\n",
    "    end_spike = np.cumsum(spike_counts)\n",
    "    start_spike = np.empty_like(end_spike)\n",
    "    start_spike[0] = 0\n",
    "    start_spike[1:] = end_spike[0:-1]\n",
    "\n",
    "    spikeTimes = np.hstack(poisson_spikes).astype(float)\n",
    "    \n",
    "    return start_spike, end_spike, spikeTimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "WAIT_FREQ = 1  # Hz\n",
    "spike_dt = 0.001\n",
    "\n",
    "TIME_FACTOR = 0.1\n",
    "\n",
    "TRAIN_SAMPLES = 60000\n",
    "TEST_SAMPLES = 10000\n",
    "TRAIN_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing neuron 0\n",
      "Processing neuron 10\n",
      "Processing neuron 20\n",
      "Processing neuron 30\n",
      "Processing neuron 40\n",
      "Processing neuron 50\n",
      "Processing neuron 60\n",
      "Processing neuron 70\n",
      "Processing neuron 80\n",
      "Processing neuron 90\n",
      "Processing neuron 100\n",
      "Processing neuron 110\n",
      "Processing neuron 120\n",
      "Processing neuron 130\n",
      "Processing neuron 140\n",
      "Processing neuron 150\n",
      "Processing neuron 160\n",
      "Processing neuron 170\n",
      "Processing neuron 180\n",
      "Processing neuron 190\n",
      "Processing neuron 200\n",
      "Processing neuron 210\n",
      "Processing neuron 220\n",
      "Processing neuron 230\n",
      "Processing neuron 240\n",
      "Processing neuron 250\n",
      "Processing neuron 260\n",
      "Processing neuron 270\n",
      "Processing neuron 280\n",
      "Processing neuron 290\n",
      "Processing neuron 300\n",
      "Processing neuron 310\n",
      "Processing neuron 320\n",
      "Processing neuron 330\n",
      "Processing neuron 340\n",
      "Processing neuron 350\n",
      "Processing neuron 360\n",
      "Processing neuron 370\n",
      "Processing neuron 380\n",
      "Processing neuron 390\n",
      "Processing neuron 400\n",
      "Processing neuron 410\n",
      "Processing neuron 420\n",
      "Processing neuron 430\n",
      "Processing neuron 440\n",
      "Processing neuron 450\n",
      "Processing neuron 460\n",
      "Processing neuron 470\n",
      "Processing neuron 480\n",
      "Processing neuron 490\n",
      "Processing neuron 500\n",
      "Processing neuron 510\n",
      "Processing neuron 520\n",
      "Processing neuron 530\n",
      "Processing neuron 540\n",
      "Processing neuron 550\n",
      "Processing neuron 560\n",
      "Processing neuron 570\n",
      "Processing neuron 580\n",
      "Processing neuron 590\n",
      "Processing neuron 600\n",
      "Processing neuron 610\n",
      "Processing neuron 620\n",
      "Processing neuron 630\n",
      "Processing neuron 640\n",
      "Processing neuron 650\n",
      "Processing neuron 660\n",
      "Processing neuron 670\n",
      "Processing neuron 680\n",
      "Processing neuron 690\n",
      "Processing neuron 700\n",
      "Processing neuron 710\n",
      "Processing neuron 720\n",
      "Processing neuron 730\n",
      "Processing neuron 740\n",
      "Processing neuron 750\n",
      "Processing neuron 760\n",
      "Processing neuron 770\n",
      "Processing neuron 780\n",
      "Processing neuron 0\n",
      "Processing neuron 10\n",
      "Processing neuron 20\n",
      "Processing neuron 30\n",
      "Processing neuron 40\n",
      "Processing neuron 50\n",
      "Processing neuron 60\n",
      "Processing neuron 70\n",
      "Processing neuron 80\n",
      "Processing neuron 90\n",
      "Processing neuron 100\n",
      "Processing neuron 110\n",
      "Processing neuron 120\n",
      "Processing neuron 130\n",
      "Processing neuron 140\n",
      "Processing neuron 150\n",
      "Processing neuron 160\n",
      "Processing neuron 170\n",
      "Processing neuron 180\n",
      "Processing neuron 190\n",
      "Processing neuron 200\n",
      "Processing neuron 210\n",
      "Processing neuron 220\n",
      "Processing neuron 230\n",
      "Processing neuron 240\n",
      "Processing neuron 250\n",
      "Processing neuron 260\n",
      "Processing neuron 270\n",
      "Processing neuron 280\n",
      "Processing neuron 290\n",
      "Processing neuron 300\n",
      "Processing neuron 310\n",
      "Processing neuron 320\n",
      "Processing neuron 330\n",
      "Processing neuron 340\n",
      "Processing neuron 350\n",
      "Processing neuron 360\n",
      "Processing neuron 370\n",
      "Processing neuron 380\n",
      "Processing neuron 390\n",
      "Processing neuron 400\n",
      "Processing neuron 410\n",
      "Processing neuron 420\n",
      "Processing neuron 430\n",
      "Processing neuron 440\n",
      "Processing neuron 450\n",
      "Processing neuron 460\n",
      "Processing neuron 470\n",
      "Processing neuron 480\n",
      "Processing neuron 490\n",
      "Processing neuron 500\n",
      "Processing neuron 510\n",
      "Processing neuron 520\n",
      "Processing neuron 530\n",
      "Processing neuron 540\n",
      "Processing neuron 550\n",
      "Processing neuron 560\n",
      "Processing neuron 570\n",
      "Processing neuron 580\n",
      "Processing neuron 590\n",
      "Processing neuron 600\n",
      "Processing neuron 610\n",
      "Processing neuron 620\n",
      "Processing neuron 630\n",
      "Processing neuron 640\n",
      "Processing neuron 650\n",
      "Processing neuron 660\n",
      "Processing neuron 670\n",
      "Processing neuron 680\n",
      "Processing neuron 690\n",
      "Processing neuron 700\n",
      "Processing neuron 710\n",
      "Processing neuron 720\n",
      "Processing neuron 730\n",
      "Processing neuron 740\n",
      "Processing neuron 750\n",
      "Processing neuron 760\n",
      "Processing neuron 770\n",
      "Processing neuron 780\n"
     ]
    }
   ],
   "source": [
    "train_start_spike, train_end_spike, train_spikeTimes = create_trials(N_INPUT, TRAIN_EPOCHS, TRAIN_SAMPLES, \n",
    "                                                                     X_train_spike, STIMULUS_TIMESTEPS, \n",
    "                                                                     WAIT_TIMESTEPS, ITI, WAIT_FREQ, \n",
    "                                                                     spike_dt, TIME_FACTOR)\n",
    "\n",
    "test_start_spike, test_end_spike, test_spikeTimes = create_trials(N_INPUT, 1, TEST_SAMPLES,\n",
    "                                                                  X_test_spike, STIMULUS_TIMESTEPS,\n",
    "                                                                  WAIT_TIMESTEPS, ITI, WAIT_FREQ, \n",
    "                                                                  spike_dt, TIME_FACTOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_start_spike.pkl\", \"wb\") as f:\n",
    "    pkl.dump(train_start_spike, f)\n",
    "with open(\"train_end_spike.pkl\", \"wb\") as f:\n",
    "    pkl.dump(train_end_spike, f)\n",
    "with open(\"train_spikeTimes.pkl\", \"wb\") as f:\n",
    "    pkl.dump(train_spikeTimes, f)\n",
    "    \n",
    "with open(\"test_start_spike.pkl\", \"wb\") as f:\n",
    "    pkl.dump(test_start_spike, f)\n",
    "with open(\"test_end_spike.pkl\", \"wb\") as f:\n",
    "    pkl.dump(test_end_spike, f)\n",
    "with open(\"test_spikeTimes.pkl\", \"wb\") as f:\n",
    "    pkl.dump(test_spikeTimes, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved data\n",
    "with open(\"train_start_spike.pkl\", \"rb\") as f:\n",
    "    train_start_spike = pkl.load(f)\n",
    "with open(\"train_end_spike.pkl\", \"rb\") as f:\n",
    "    train_end_spike = pkl.load(f)\n",
    "with open(\"train_spikeTimes.pkl\", \"rb\") as f:\n",
    "    train_spikeTimes = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved data\n",
    "with open(\"test_start_spike.pkl\", \"rb\") as f:\n",
    "    test_start_spike = pkl.load(f)\n",
    "with open(\"test_end_spike.pkl\", \"rb\") as f:\n",
    "    test_end_spike = pkl.load(f)\n",
    "with open(\"test_spikeTimes.pkl\", \"rb\") as f:\n",
    "    test_spikeTimes = pkl.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_HIDDEN = 1024\n",
    "N_OUTPUT = 10\n",
    "update_time = 500  # ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssa_input_model = genn_model.create_custom_neuron_class(\n",
    "    \"ssa_input_model\",\n",
    "    param_names=[\"t_rise\", \"t_decay\"],\n",
    "    var_name_types=[(\"startSpike\", \"unsigned int\"), (\"endSpike\", \"unsigned int\"),\n",
    "                    (\"z\", \"scalar\"), (\"z_tilda\", \"scalar\")],\n",
    "    sim_code=\"\"\"\n",
    "    // filtered presynaptic trace\n",
    "    // $(z) *= exp(- DT / $(t_rise));\n",
    "    $(z) += (- $(z) / $(t_rise)) * DT;\n",
    "    $(z_tilda) += ((- $(z_tilda) + $(z)) / $(t_decay)) * DT;\n",
    "    if ($(z_tilda) < 0.0000001) {\n",
    "        $(z_tilda) = 0.0;\n",
    "    }\n",
    "    \"\"\",\n",
    "    reset_code=\"\"\"\n",
    "    $(startSpike)++;\n",
    "    $(z) += 1.0;\n",
    "    \"\"\",\n",
    "    threshold_condition_code=\"$(startSpike) != $(endSpike) && $(t)>= $(spikeTimes)[$(startSpike)]\",\n",
    "    extra_global_params=[(\"spikeTimes\", \"scalar*\")],\n",
    "    is_auto_refractory_required=False\n",
    ")\n",
    "\n",
    "SSA_INPUT_PARAMS = {\"t_rise\": 5, \"t_decay\": 10}\n",
    "\n",
    "ssa_input_init = {\"startSpike\": train_start_spike,\n",
    "                  \"endSpike\": train_end_spike,\n",
    "                  \"z\": 0.0,\n",
    "                  \"z_tilda\": 0.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_FACTOR = 0.1\n",
    "\n",
    "TRAIN_SAMPLES = 60000\n",
    "TEST_SAMPLES = 10000\n",
    "TRAIN_EPOCHS = 5\n",
    "\n",
    "N_INPUT = 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n"
     ]
    }
   ],
   "source": [
    "print(\"Building model...\")\n",
    "\n",
    "model = genn_model.GeNNModel(precision=\"float\", model_name=\"train\", time_precision=\"double\")\n",
    "model.dT = 1.0 * TIME_FACTOR\n",
    "\n",
    "inp = model.add_neuron_population(\"inp\", N_INPUT, ssa_input_model, SSA_INPUT_PARAMS, ssa_input_init)\n",
    "inp.set_extra_global_param(\"spikeTimes\", train_spikeTimes)\n",
    "\n",
    "hid = model.add_neuron_population(\"hid\", N_HIDDEN, hidden_model, HIDDEN_PARAMS, hidden_init)\n",
    "\n",
    "out = model.add_neuron_population(\"out\", N_OUTPUT, output_model_classification, OUTPUT_PARAMS,\n",
    "                                  output_init_classification)\n",
    "\n",
    "inp2hid = model.add_synapse_population(\"inp2hid\", \"DENSE_INDIVIDUALG\", genn_wrapper.NO_DELAY,\n",
    "                                       inp, hid,\n",
    "                                       superspike_model, SUPERSPIKE_PARAMS, superspike_init, {}, {},\n",
    "                                       \"ExpCurr\", {\"tau\": 5.0}, {})\n",
    "\n",
    "hid2out = model.add_synapse_population(\"hid2out\", \"DENSE_INDIVIDUALG\", genn_wrapper.NO_DELAY,\n",
    "                                       hid, out,\n",
    "                                       superspike_model, SUPERSPIKE_PARAMS, superspike_init, {}, {},\n",
    "                                       \"ExpCurr\", {\"tau\": 5.0}, {})\n",
    "\n",
    "out2hid = model.add_synapse_population(\"out2hid\", \"DENSE_INDIVIDUALG\", genn_wrapper.NO_DELAY,\n",
    "                                       out, hid,\n",
    "                                       feedback_wts_model, {}, feedback_wts_init, {}, {},\n",
    "                                       feedback_postsyn_model, {}, {})\n",
    "\n",
    "model.build()\n",
    "model.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 10.0\n",
    "b = 5.0\n",
    "tau_avg_err = 10.0\n",
    "scale_tr_err_flt = 1.0 / ((((a * b) / (a - b)) ** 2) * (a / 2 + b / 2 - 2 * (a * b) / (a + b))) / tau_avg_err\n",
    "mul_avgsqrerr = np.exp(-TIME_FACTOR / tau_avg_err)\n",
    "record_avgsqerr = np.empty(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_voltage = out.vars['V'].view\n",
    "out_window_of_opp = out.vars[\"window_of_opp\"].view\n",
    "out_S_pred = out.vars['S_pred'].view\n",
    "out_S_miss = out.vars['S_miss'].view\n",
    "hid_err_tilda = hid.vars['err_tilda'].view\n",
    "out_err_tilda = out.vars['err_tilda'].view\n",
    "inp_z = inp.vars['z'].view\n",
    "inp_z_tilda = inp.vars[\"z_tilda\"].view\n",
    "hid_z = hid.vars['z'].view\n",
    "hid_z_tilda = hid.vars['z_tilda'].view\n",
    "hid_voltage = hid.vars['V'].view\n",
    "inp2hid_lambda = inp2hid.vars['lambda'].view\n",
    "hid2out_lambda = hid2out.vars['lambda'].view\n",
    "inp2hid_e = inp2hid.vars['e'].view\n",
    "hid2out_e = hid2out.vars['e'].view\n",
    "out_err_rise = out.vars[\"err_rise\"].view\n",
    "out_err_decay = out.vars[\"err_decay\"].view\n",
    "\n",
    "# set feedback weights equal to feedforward weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting simulation\n",
      "Epoch: 0\n",
      "\n",
      "\n",
      "Sample: 0\n",
      "\n",
      "\n",
      "Sample: 1000\n",
      "\n",
      "\n",
      "Sample: 2000\n",
      "\n",
      "\n",
      "Sample: 3000\n",
      "\n",
      "\n",
      "Sample: 4000\n",
      "\n",
      "\n",
      "Sample: 5000\n",
      "\n",
      "\n",
      "Sample: 6000\n",
      "\n",
      "\n",
      "Sample: 7000\n",
      "\n",
      "\n",
      "Sample: 8000\n",
      "\n",
      "\n",
      "Sample: 9000\n",
      "\n",
      "\n",
      "Sample: 10000\n",
      "\n",
      "\n",
      "Sample: 11000\n",
      "\n",
      "\n",
      "Sample: 12000\n",
      "\n",
      "\n",
      "Sample: 13000\n",
      "\n",
      "\n",
      "Sample: 14000\n",
      "\n",
      "\n",
      "Sample: 15000\n",
      "\n",
      "\n",
      "Sample: 16000\n",
      "\n",
      "\n",
      "Sample: 17000\n",
      "\n",
      "\n",
      "Sample: 18000\n",
      "\n",
      "\n",
      "Sample: 19000\n",
      "\n",
      "\n",
      "Sample: 20000\n",
      "\n",
      "\n",
      "Sample: 21000\n",
      "\n",
      "\n",
      "Sample: 22000\n",
      "\n",
      "\n",
      "Sample: 23000\n",
      "\n",
      "\n",
      "Sample: 24000\n",
      "\n",
      "\n",
      "Sample: 25000\n",
      "\n",
      "\n",
      "Sample: 26000\n",
      "\n",
      "\n",
      "Sample: 27000\n",
      "\n",
      "\n",
      "Sample: 28000\n",
      "\n",
      "\n",
      "Sample: 29000\n",
      "\n",
      "\n",
      "Sample: 30000\n",
      "\n",
      "\n",
      "Sample: 31000\n",
      "\n",
      "\n",
      "Sample: 32000\n",
      "\n",
      "\n",
      "Sample: 33000\n",
      "\n",
      "\n",
      "Sample: 34000\n",
      "\n",
      "\n",
      "Sample: 35000\n",
      "\n",
      "\n",
      "Sample: 36000\n",
      "\n",
      "\n",
      "Sample: 37000\n",
      "\n",
      "\n",
      "Sample: 38000\n",
      "\n",
      "\n",
      "Sample: 39000\n",
      "\n",
      "\n",
      "Sample: 40000\n",
      "\n",
      "\n",
      "Sample: 41000\n",
      "\n",
      "\n",
      "Sample: 42000\n",
      "\n",
      "\n",
      "Sample: 43000\n",
      "\n",
      "\n",
      "Sample: 44000\n",
      "\n",
      "\n",
      "Sample: 45000\n",
      "\n",
      "\n",
      "Sample: 46000\n",
      "\n",
      "\n",
      "Sample: 47000\n",
      "\n",
      "\n",
      "Sample: 48000\n",
      "\n",
      "\n",
      "Sample: 49000\n",
      "\n",
      "\n",
      "Sample: 50000\n",
      "\n",
      "\n",
      "Sample: 51000\n",
      "\n",
      "\n",
      "Sample: 52000\n",
      "\n",
      "\n",
      "Sample: 53000\n",
      "\n",
      "\n",
      "Sample: 54000\n",
      "\n",
      "\n",
      "Sample: 55000\n",
      "\n",
      "\n",
      "Sample: 56000\n",
      "\n",
      "\n",
      "Sample: 57000\n",
      "\n",
      "\n",
      "Sample: 58000\n",
      "\n",
      "\n",
      "Sample: 59000\n",
      "Epoch: 1\n",
      "\n",
      "\n",
      "Sample: 0\n",
      "\n",
      "\n",
      "Sample: 1000\n",
      "\n",
      "\n",
      "Sample: 2000\n",
      "\n",
      "\n",
      "Sample: 3000\n",
      "\n",
      "\n",
      "Sample: 4000\n",
      "\n",
      "\n",
      "Sample: 5000\n",
      "\n",
      "\n",
      "Sample: 6000\n",
      "\n",
      "\n",
      "Sample: 7000\n",
      "\n",
      "\n",
      "Sample: 8000\n",
      "\n",
      "\n",
      "Sample: 9000\n",
      "\n",
      "\n",
      "Sample: 10000\n",
      "\n",
      "\n",
      "Sample: 11000\n",
      "\n",
      "\n",
      "Sample: 12000\n",
      "\n",
      "\n",
      "Sample: 13000\n",
      "\n",
      "\n",
      "Sample: 14000\n",
      "\n",
      "\n",
      "Sample: 15000\n",
      "\n",
      "\n",
      "Sample: 16000\n",
      "\n",
      "\n",
      "Sample: 17000\n",
      "\n",
      "\n",
      "Sample: 18000\n",
      "\n",
      "\n",
      "Sample: 19000\n",
      "\n",
      "\n",
      "Sample: 20000\n",
      "\n",
      "\n",
      "Sample: 21000\n",
      "\n",
      "\n",
      "Sample: 22000\n",
      "\n",
      "\n",
      "Sample: 23000\n",
      "\n",
      "\n",
      "Sample: 24000\n",
      "\n",
      "\n",
      "Sample: 25000\n",
      "\n",
      "\n",
      "Sample: 26000\n",
      "\n",
      "\n",
      "Sample: 27000\n",
      "\n",
      "\n",
      "Sample: 28000\n",
      "\n",
      "\n",
      "Sample: 29000\n",
      "\n",
      "\n",
      "Sample: 30000\n",
      "\n",
      "\n",
      "Sample: 31000\n",
      "\n",
      "\n",
      "Sample: 32000\n",
      "\n",
      "\n",
      "Sample: 33000\n",
      "\n",
      "\n",
      "Sample: 34000\n",
      "\n",
      "\n",
      "Sample: 35000\n",
      "\n",
      "\n",
      "Sample: 36000\n",
      "\n",
      "\n",
      "Sample: 37000\n",
      "\n",
      "\n",
      "Sample: 38000\n",
      "\n",
      "\n",
      "Sample: 39000\n",
      "\n",
      "\n",
      "Sample: 40000\n",
      "\n",
      "\n",
      "Sample: 41000\n",
      "\n",
      "\n",
      "Sample: 42000\n",
      "\n",
      "\n",
      "Sample: 43000\n",
      "\n",
      "\n",
      "Sample: 44000\n",
      "\n",
      "\n",
      "Sample: 45000\n",
      "\n",
      "\n",
      "Sample: 46000\n",
      "\n",
      "\n",
      "Sample: 47000\n",
      "\n",
      "\n",
      "Sample: 48000\n",
      "\n",
      "\n",
      "Sample: 49000\n",
      "\n",
      "\n",
      "Sample: 50000\n",
      "\n",
      "\n",
      "Sample: 51000\n",
      "\n",
      "\n",
      "Sample: 52000\n",
      "\n",
      "\n",
      "Sample: 53000\n",
      "\n",
      "\n",
      "Sample: 54000\n",
      "\n",
      "\n",
      "Sample: 55000\n",
      "\n",
      "\n",
      "Sample: 56000\n",
      "\n",
      "\n",
      "Sample: 57000\n",
      "\n",
      "\n",
      "Sample: 58000\n",
      "\n",
      "\n",
      "Sample: 59000\n",
      "Epoch: 2\n",
      "\n",
      "\n",
      "Sample: 0\n",
      "\n",
      "\n",
      "Sample: 1000\n",
      "\n",
      "\n",
      "Sample: 2000\n",
      "\n",
      "\n",
      "Sample: 3000\n",
      "\n",
      "\n",
      "Sample: 4000\n",
      "\n",
      "\n",
      "Sample: 5000\n",
      "\n",
      "\n",
      "Sample: 6000\n",
      "\n",
      "\n",
      "Sample: 7000\n",
      "\n",
      "\n",
      "Sample: 8000\n",
      "\n",
      "\n",
      "Sample: 9000\n",
      "\n",
      "\n",
      "Sample: 10000\n",
      "\n",
      "\n",
      "Sample: 11000\n",
      "\n",
      "\n",
      "Sample: 12000\n",
      "\n",
      "\n",
      "Sample: 13000\n",
      "\n",
      "\n",
      "Sample: 14000\n",
      "\n",
      "\n",
      "Sample: 15000\n",
      "\n",
      "\n",
      "Sample: 16000\n",
      "\n",
      "\n",
      "Sample: 17000\n",
      "\n",
      "\n",
      "Sample: 18000\n",
      "\n",
      "\n",
      "Sample: 19000\n",
      "\n",
      "\n",
      "Sample: 20000\n",
      "\n",
      "\n",
      "Sample: 21000\n",
      "\n",
      "\n",
      "Sample: 22000\n",
      "\n",
      "\n",
      "Sample: 23000\n",
      "\n",
      "\n",
      "Sample: 24000\n",
      "\n",
      "\n",
      "Sample: 25000\n",
      "\n",
      "\n",
      "Sample: 26000\n",
      "\n",
      "\n",
      "Sample: 27000\n",
      "\n",
      "\n",
      "Sample: 28000\n",
      "\n",
      "\n",
      "Sample: 29000\n",
      "\n",
      "\n",
      "Sample: 30000\n",
      "\n",
      "\n",
      "Sample: 31000\n",
      "\n",
      "\n",
      "Sample: 32000\n",
      "\n",
      "\n",
      "Sample: 33000\n",
      "\n",
      "\n",
      "Sample: 34000\n",
      "\n",
      "\n",
      "Sample: 35000\n",
      "\n",
      "\n",
      "Sample: 36000\n",
      "\n",
      "\n",
      "Sample: 37000\n",
      "\n",
      "\n",
      "Sample: 38000\n",
      "\n",
      "\n",
      "Sample: 39000\n",
      "\n",
      "\n",
      "Sample: 40000\n",
      "\n",
      "\n",
      "Sample: 41000\n",
      "\n",
      "\n",
      "Sample: 42000\n",
      "\n",
      "\n",
      "Sample: 43000\n",
      "\n",
      "\n",
      "Sample: 44000\n",
      "\n",
      "\n",
      "Sample: 45000\n",
      "\n",
      "\n",
      "Sample: 46000\n",
      "\n",
      "\n",
      "Sample: 47000\n",
      "\n",
      "\n",
      "Sample: 48000\n",
      "\n",
      "\n",
      "Sample: 49000\n",
      "\n",
      "\n",
      "Sample: 50000\n",
      "\n",
      "\n",
      "Sample: 51000\n",
      "\n",
      "\n",
      "Sample: 52000\n",
      "\n",
      "\n",
      "Sample: 53000\n",
      "\n",
      "\n",
      "Sample: 54000\n",
      "\n",
      "\n",
      "Sample: 55000\n",
      "\n",
      "\n",
      "Sample: 56000\n",
      "\n",
      "\n",
      "Sample: 57000\n",
      "\n",
      "\n",
      "Sample: 58000\n",
      "\n",
      "\n",
      "Sample: 59000\n",
      "Epoch: 3\n",
      "\n",
      "\n",
      "Sample: 0\n",
      "\n",
      "\n",
      "Sample: 1000\n",
      "\n",
      "\n",
      "Sample: 2000\n",
      "\n",
      "\n",
      "Sample: 3000\n",
      "\n",
      "\n",
      "Sample: 4000\n",
      "\n",
      "\n",
      "Sample: 5000\n",
      "\n",
      "\n",
      "Sample: 6000\n",
      "\n",
      "\n",
      "Sample: 7000\n",
      "\n",
      "\n",
      "Sample: 8000\n",
      "\n",
      "\n",
      "Sample: 9000\n",
      "\n",
      "\n",
      "Sample: 10000\n",
      "\n",
      "\n",
      "Sample: 11000\n",
      "\n",
      "\n",
      "Sample: 12000\n",
      "\n",
      "\n",
      "Sample: 13000\n",
      "\n",
      "\n",
      "Sample: 14000\n",
      "\n",
      "\n",
      "Sample: 15000\n",
      "\n",
      "\n",
      "Sample: 16000\n",
      "\n",
      "\n",
      "Sample: 17000\n",
      "\n",
      "\n",
      "Sample: 18000\n",
      "\n",
      "\n",
      "Sample: 19000\n",
      "\n",
      "\n",
      "Sample: 20000\n",
      "\n",
      "\n",
      "Sample: 21000\n",
      "\n",
      "\n",
      "Sample: 22000\n",
      "\n",
      "\n",
      "Sample: 23000\n",
      "\n",
      "\n",
      "Sample: 24000\n",
      "\n",
      "\n",
      "Sample: 25000\n",
      "\n",
      "\n",
      "Sample: 26000\n",
      "\n",
      "\n",
      "Sample: 27000\n",
      "\n",
      "\n",
      "Sample: 28000\n",
      "\n",
      "\n",
      "Sample: 29000\n",
      "\n",
      "\n",
      "Sample: 30000\n",
      "\n",
      "\n",
      "Sample: 31000\n",
      "\n",
      "\n",
      "Sample: 32000\n",
      "\n",
      "\n",
      "Sample: 33000\n",
      "\n",
      "\n",
      "Sample: 34000\n",
      "\n",
      "\n",
      "Sample: 35000\n",
      "\n",
      "\n",
      "Sample: 36000\n",
      "\n",
      "\n",
      "Sample: 37000\n",
      "\n",
      "\n",
      "Sample: 38000\n",
      "\n",
      "\n",
      "Sample: 39000\n",
      "\n",
      "\n",
      "Sample: 40000\n",
      "\n",
      "\n",
      "Sample: 41000\n",
      "\n",
      "\n",
      "Sample: 42000\n",
      "\n",
      "\n",
      "Sample: 43000\n",
      "\n",
      "\n",
      "Sample: 44000\n",
      "\n",
      "\n",
      "Sample: 45000\n",
      "\n",
      "\n",
      "Sample: 46000\n",
      "\n",
      "\n",
      "Sample: 47000\n",
      "\n",
      "\n",
      "Sample: 48000\n",
      "\n",
      "\n",
      "Sample: 49000\n",
      "\n",
      "\n",
      "Sample: 50000\n",
      "\n",
      "\n",
      "Sample: 51000\n",
      "\n",
      "\n",
      "Sample: 52000\n",
      "\n",
      "\n",
      "Sample: 53000\n",
      "\n",
      "\n",
      "Sample: 54000\n",
      "\n",
      "\n",
      "Sample: 55000\n",
      "\n",
      "\n",
      "Sample: 56000\n",
      "\n",
      "\n",
      "Sample: 57000\n",
      "\n",
      "\n",
      "Sample: 58000\n",
      "\n",
      "\n",
      "Sample: 59000\n",
      "Epoch: 4\n",
      "\n",
      "\n",
      "Sample: 0\n",
      "\n",
      "\n",
      "Sample: 1000\n",
      "\n",
      "\n",
      "Sample: 2000\n",
      "\n",
      "\n",
      "Sample: 3000\n",
      "\n",
      "\n",
      "Sample: 4000\n",
      "\n",
      "\n",
      "Sample: 5000\n",
      "\n",
      "\n",
      "Sample: 6000\n",
      "\n",
      "\n",
      "Sample: 7000\n",
      "\n",
      "\n",
      "Sample: 8000\n",
      "\n",
      "\n",
      "Sample: 9000\n",
      "\n",
      "\n",
      "Sample: 10000\n",
      "\n",
      "\n",
      "Sample: 11000\n",
      "\n",
      "\n",
      "Sample: 12000\n",
      "\n",
      "\n",
      "Sample: 13000\n",
      "\n",
      "\n",
      "Sample: 14000\n",
      "\n",
      "\n",
      "Sample: 15000\n",
      "\n",
      "\n",
      "Sample: 16000\n",
      "\n",
      "\n",
      "Sample: 17000\n",
      "\n",
      "\n",
      "Sample: 18000\n",
      "\n",
      "\n",
      "Sample: 19000\n",
      "\n",
      "\n",
      "Sample: 20000\n",
      "\n",
      "\n",
      "Sample: 21000\n",
      "\n",
      "\n",
      "Sample: 22000\n",
      "\n",
      "\n",
      "Sample: 23000\n",
      "\n",
      "\n",
      "Sample: 24000\n",
      "\n",
      "\n",
      "Sample: 25000\n",
      "\n",
      "\n",
      "Sample: 26000\n",
      "\n",
      "\n",
      "Sample: 27000\n",
      "\n",
      "\n",
      "Sample: 28000\n",
      "\n",
      "\n",
      "Sample: 29000\n",
      "\n",
      "\n",
      "Sample: 30000\n",
      "\n",
      "\n",
      "Sample: 31000\n",
      "\n",
      "\n",
      "Sample: 32000\n",
      "\n",
      "\n",
      "Sample: 33000\n",
      "\n",
      "\n",
      "Sample: 34000\n",
      "\n",
      "\n",
      "Sample: 35000\n",
      "\n",
      "\n",
      "Sample: 36000\n",
      "\n",
      "\n",
      "Sample: 37000\n",
      "\n",
      "\n",
      "Sample: 38000\n",
      "\n",
      "\n",
      "Sample: 39000\n",
      "\n",
      "\n",
      "Sample: 40000\n",
      "\n",
      "\n",
      "Sample: 41000\n",
      "\n",
      "\n",
      "Sample: 42000\n",
      "\n",
      "\n",
      "Sample: 43000\n",
      "\n",
      "\n",
      "Sample: 44000\n",
      "\n",
      "\n",
      "Sample: 45000\n",
      "\n",
      "\n",
      "Sample: 46000\n",
      "\n",
      "\n",
      "Sample: 47000\n",
      "\n",
      "\n",
      "Sample: 48000\n",
      "\n",
      "\n",
      "Sample: 49000\n",
      "\n",
      "\n",
      "Sample: 50000\n",
      "\n",
      "\n",
      "Sample: 51000\n",
      "\n",
      "\n",
      "Sample: 52000\n",
      "\n",
      "\n",
      "Sample: 53000\n",
      "\n",
      "\n",
      "Sample: 54000\n",
      "\n",
      "\n",
      "Sample: 55000\n",
      "\n",
      "\n",
      "Sample: 56000\n",
      "\n",
      "\n",
      "Sample: 57000\n",
      "\n",
      "\n",
      "Sample: 58000\n",
      "\n",
      "\n",
      "Sample: 59000\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting simulation\")\n",
    "\n",
    "for epoch in range(TRAIN_EPOCHS):\n",
    "\n",
    "    print(\"Epoch: \" + str(epoch))\n",
    "\n",
    "    for trial in range(TRAIN_SAMPLES):\n",
    "\n",
    "        if trial % 1000 == 0:\n",
    "            print(\"\\n\")\n",
    "            print(\"Sample: \" + str(trial))\n",
    "\n",
    "        # Important to record for this trial\n",
    "        target = y_train[trial]\n",
    "\n",
    "        # Reinitialize or provide correct values for different variables at the start of the next trial\n",
    "        out_voltage[:] = OUTPUT_PARAMS[\"Vrest\"]\n",
    "        model.push_var_to_device('out', \"V\")\n",
    "        inp_z[:] = ssa_input_init['z']\n",
    "        model.push_var_to_device(\"inp\", \"z\")\n",
    "        inp_z_tilda[:] = ssa_input_init[\"z_tilda\"]\n",
    "        model.push_var_to_device(\"inp\", \"z_tilda\")\n",
    "        hid_z[:] = hidden_init['z']\n",
    "        model.push_var_to_device(\"hid\", \"z\")\n",
    "        hid_z_tilda[:] = hidden_init['z_tilda']\n",
    "        model.push_var_to_device(\"hid\", \"z_tilda\")\n",
    "        hid_voltage[:] = HIDDEN_PARAMS[\"Vrest\"]\n",
    "        model.push_var_to_device(\"hid\", \"V\")\n",
    "        hid2out_lambda[:] = 0.0\n",
    "        model.push_var_to_device(\"hid2out\", \"lambda\")\n",
    "        inp2hid_lambda[:] = 0.0\n",
    "        model.push_var_to_device(\"inp2hid\", \"lambda\")\n",
    "        hid2out_e[:] = 0.0\n",
    "        model.push_var_to_device(\"hid2out\", \"e\")\n",
    "        inp2hid_e[:] = 0.0\n",
    "        model.push_var_to_device(\"inp2hid\", \"e\")\n",
    "        out_err_tilda[:] = 0.0\n",
    "        model.push_var_to_device('out', 'err_tilda')\n",
    "        hid_err_tilda[:] = 0.0\n",
    "        model.push_var_to_device('hid', 'err_tilda')\n",
    "        out_err_rise[:] = 0.0\n",
    "        model.push_var_to_device('out', 'err_rise')\n",
    "        out_err_decay[:] = 0.0\n",
    "        model.push_var_to_device('out', 'err_decay')\n",
    "\n",
    "        # Indicate the correct values for window_of_opp, S_pred, and S_miss before the stimulus is presented\n",
    "        out_window_of_opp[:] = 1.0\n",
    "        model.push_var_to_device(\"out\", \"window_of_opp\")\n",
    "\n",
    "        S_pred = np.zeros(N_OUTPUT)\n",
    "        S_pred[target] = 1.0\n",
    "        out_S_pred[:] = S_pred\n",
    "        model.push_var_to_device(\"out\", \"S_pred\")\n",
    "\n",
    "        out_S_miss[:] = 0.0\n",
    "        model.push_var_to_device(\"out\", \"S_miss\")\n",
    "        \n",
    "        produced_spikes = []\n",
    "\n",
    "        steps = int(total_time / TIME_FACTOR)\n",
    "\n",
    "        for t in range(steps):\n",
    "\n",
    "            if t == ((STIMULUS_TIMESTEPS + WAIT_TIMESTEPS) / TIME_FACTOR):\n",
    "                out_window_of_opp[:] = 0.0\n",
    "                model.push_var_to_device(\"out\", \"window_of_opp\")\n",
    "\n",
    "                if len(produced_spikes) == 0:\n",
    "                    out_S_miss[:] = 1.0\n",
    "                    model.push_var_to_device(\"out\", \"S_miss\")\n",
    "\n",
    "            model.step_time()\n",
    "\n",
    "            if t == ((STIMULUS_TIMESTEPS + WAIT_TIMESTEPS) / TIME_FACTOR):\n",
    "                out_S_miss[:] = 0.0\n",
    "                model.push_var_to_device(\"out\", \"S_miss\")\n",
    "\n",
    "            model.pull_current_spikes_from_device(\"out\")\n",
    "            if target in out.current_spikes:\n",
    "                produced_spikes.append(model.t)\n",
    "\n",
    "            if model.t % update_time == 0 and model.t != 0:\n",
    "                # We calculate the total average square error\n",
    "                model.pull_var_from_device(\"out\", \"avg_sq_err\")\n",
    "                avgsqrerr = out.vars[\"avg_sq_err\"].view[:]\n",
    "                error = get_mean_square_error(scale_tr_err_flt, avgsqrerr, model.t, tau_avg_err)\n",
    "                record_avgsqerr = np.hstack((record_avgsqerr, error))\n",
    "                out.vars[\"avg_sq_err\"].view[:] = np.zeros(shape=N_OUTPUT)\n",
    "                model.push_var_to_device(\"out\", \"avg_sq_err\")\n",
    "                \n",
    "                # update feedback weights\n",
    "                model.pull_var_from_device(\"hid2out\", \"w\")\n",
    "                h2o_weights = hid2out.get_var_values(\"w\")\n",
    "                h2o_weights = np.reshape(h2o_weights, newshape=(N_HIDDEN, N_OUTPUT))\n",
    "                h2o_weights = np.transpose(h2o_weights).flatten()\n",
    "                out2hid.vars['g'].view[:] = h2o_weights\n",
    "                model.push_var_to_device(\"out2hid\", \"g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.pull_var_from_device(\"inp2hid\", \"w\")\n",
    "inp2hid_to_test = inp2hid.vars[\"w\"].view[:].flatten()\n",
    "model.pull_var_from_device(\"hid2out\", \"w\")\n",
    "hid2out_to_test = hid2out.vars[\"w\"].view[:].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"record_avgsqerr.pkl\", \"wb\") as f:\n",
    "    pkl.dump(record_avgsqerr, f)\n",
    "with open(\"inp2hid_to_test.pkl\", \"wb\") as f:\n",
    "    pkl.dump(inp2hid_to_test, f)\n",
    "with open(\"hid2out_to_test.pkl\", \"wb\") as f:\n",
    "    pkl.dump(hid2out_to_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.plot(list(range(len(record_avgsqerr))), record_avgsqerr)\n",
    "ax.set_xlabel(\"Time (update intervals)\")\n",
    "ax.set_ylabel(\"Error\")\n",
    "plt.show()\n",
    "# might be nicer to show this after smoothing e.g. with a moving average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssa_input_init = {\"startSpike\": test_start_spike,\n",
    "                  \"endSpike\": test_end_spike,\n",
    "                  \"z\": 0.0,\n",
    "                  \"z_tilda\": 0.0}\n",
    "\n",
    "model = genn_model.GeNNModel(precision=\"float\", model_name=\"train\", time_precision=\"double\")\n",
    "model.dT = 1.0 * TIME_FACTOR\n",
    "\n",
    "inp = model.add_neuron_population(\"inp\", N_INPUT, ssa_input_model, SSA_INPUT_PARAMS, ssa_input_init)\n",
    "inp.set_extra_global_param(\"spikeTimes\", test_spikeTimes)\n",
    "\n",
    "hid = model.add_neuron_population(\"hid\", N_HIDDEN, hidden_model, HIDDEN_PARAMS, hidden_init)\n",
    "\n",
    "out = model.add_neuron_population(\"out\", N_OUTPUT, output_model_classification, OUTPUT_PARAMS,\n",
    "                                  output_init_classification)\n",
    "\n",
    "inp2hid = model.add_synapse_population(\"inp2hid\", \"DENSE_INDIVIDUALG\",\n",
    "                                               genn_wrapper.NO_DELAY,\n",
    "                                               inp, hid,\n",
    "                                               \"StaticPulse\", {}, {\"g\": inp2hid_to_test}, {},\n",
    "                                               {},\n",
    "                                               \"ExpCurr\", {\"tau\": 5.0}, {})\n",
    "\n",
    "hid2out = model.add_synapse_population(\"hid2out\", \"DENSE_INDIVIDUALG\",\n",
    "                                               genn_wrapper.NO_DELAY,\n",
    "                                               hid, out,\n",
    "                                               \"StaticPulse\", {}, {\"g\": hid2out_to_test}, {},\n",
    "                                               {},\n",
    "                                               \"ExpCurr\", {\"tau\": 5.0}, {})\n",
    "\n",
    "model.build()\n",
    "model.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      "Sample: 0\n",
      "Sample: 100\n",
      "Sample: 200\n",
      "Sample: 300\n",
      "Sample: 400\n",
      "Sample: 500\n",
      "Sample: 600\n",
      "Sample: 700\n",
      "Sample: 800\n",
      "Sample: 900\n",
      "Sample: 1000\n",
      "Sample: 1100\n",
      "Sample: 1200\n",
      "Sample: 1300\n",
      "Sample: 1400\n",
      "Sample: 1500\n",
      "Sample: 1600\n",
      "Sample: 1700\n",
      "Sample: 1800\n",
      "Sample: 1900\n",
      "Sample: 2000\n",
      "Sample: 2100\n",
      "Sample: 2200\n",
      "Sample: 2300\n",
      "Sample: 2400\n",
      "Sample: 2500\n",
      "Sample: 2600\n",
      "Sample: 2700\n",
      "Sample: 2800\n",
      "Sample: 2900\n",
      "Sample: 3000\n",
      "Sample: 3100\n",
      "Sample: 3200\n",
      "Sample: 3300\n",
      "Sample: 3400\n",
      "Sample: 3500\n",
      "Sample: 3600\n",
      "Sample: 3700\n",
      "Sample: 3800\n",
      "Sample: 3900\n",
      "Sample: 4000\n",
      "Sample: 4100\n",
      "Sample: 4200\n",
      "Sample: 4300\n",
      "Sample: 4400\n",
      "Sample: 4500\n",
      "Sample: 4600\n",
      "Sample: 4700\n",
      "Sample: 4800\n",
      "Sample: 4900\n",
      "Sample: 5000\n",
      "Sample: 5100\n",
      "Sample: 5200\n",
      "Sample: 5300\n",
      "Sample: 5400\n",
      "Sample: 5500\n",
      "Sample: 5600\n",
      "Sample: 5700\n",
      "Sample: 5800\n",
      "Sample: 5900\n",
      "Sample: 6000\n",
      "Sample: 6100\n",
      "Sample: 6200\n",
      "Sample: 6300\n",
      "Sample: 6400\n",
      "Sample: 6500\n",
      "Sample: 6600\n",
      "Sample: 6700\n",
      "Sample: 6800\n",
      "Sample: 6900\n",
      "Sample: 7000\n",
      "Sample: 7100\n",
      "Sample: 7200\n",
      "Sample: 7300\n",
      "Sample: 7400\n",
      "Sample: 7500\n",
      "Sample: 7600\n",
      "Sample: 7700\n",
      "Sample: 7800\n",
      "Sample: 7900\n",
      "Sample: 8000\n",
      "Sample: 8100\n",
      "Sample: 8200\n",
      "Sample: 8300\n",
      "Sample: 8400\n",
      "Sample: 8500\n",
      "Sample: 8600\n",
      "Sample: 8700\n",
      "Sample: 8800\n",
      "Sample: 8900\n",
      "Sample: 9000\n",
      "Sample: 9100\n",
      "Sample: 9200\n",
      "Sample: 9300\n",
      "Sample: 9400\n",
      "Sample: 9500\n",
      "Sample: 9600\n",
      "Sample: 9700\n",
      "Sample: 9800\n",
      "Sample: 9900\n",
      "Accuracy: 0.007\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing...\")\n",
    "\n",
    "num_correct = 0\n",
    "\n",
    "for sample_idx in range(TEST_SAMPLES):\n",
    "    \n",
    "    if sample_idx % 100 == 0:\n",
    "        print(\"Sample: \" + str(sample_idx))\n",
    "    \n",
    "    test_target = y_test[sample_idx]  # target class 0 to 9\n",
    "    test_target_spikes = []\n",
    "    test_non_target_spikes = []\n",
    "\n",
    "    test_steps = int((STIMULUS_TIMESTEPS + WAIT_TIMESTEPS + ITI) / TIME_FACTOR)\n",
    "\n",
    "    for test_t in range(test_steps):\n",
    "        \n",
    "        model.step_time()\n",
    "\n",
    "        if test_t < int((STIMULUS_TIMESTEPS + WAIT_TIMESTEPS) / TIME_FACTOR):\n",
    "            model.pull_current_spikes_from_device(\"out\")\n",
    "            if test_target in out.current_spikes:\n",
    "                test_target_spikes.append(model.t)\n",
    "            else:\n",
    "                if len(out.current_spikes) != 0:\n",
    "                    test_non_target_spikes.append(model.t)\n",
    "\n",
    "    if len(test_target_spikes) != 0 and len(test_non_target_spikes) == 0:\n",
    "        num_correct += 1\n",
    "\n",
    "accuracy = num_correct / TEST_SAMPLES\n",
    "print(\"Accuracy: \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
